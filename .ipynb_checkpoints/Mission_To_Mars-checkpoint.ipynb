{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d001191-6e09-4982-a717-e9caf06db0fd",
   "metadata": {},
   "source": [
    "## MISSION TO MARS\n",
    "### Scrape Mars Data: The News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71af623a-523b-4ff3-a22e-1e9a09e95204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Splinter and BeautifulSoup\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Instead of scraping each row or data in table, scrape the entire table with Pandas' .read_html() function.\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b65a15-8609-4b62-89df-2cf9d6b85386",
   "metadata": {},
   "source": [
    "Set up the executable path and initialize a browser. With these two lines of code, we are creating an instance of a Splinter browser.  This means that we're prepping our automated browser.  We're also specifying that we'll be using Chrome as our browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e006da4-7b5e-4de0-9eb1-a9dae7ed59b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 92.0.4515\n",
      "Get LATEST driver version for 92.0.4515\n",
      "Driver [C:\\Users\\Daniel Brock\\.wdm\\drivers\\chromedriver\\win32\\92.0.4515.107\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "# Set your executable path via Splinter\n",
    "# Then set up the URL 'https://redplanetscience.com/' for scraping\n",
    "    #**executable_path is unpacking the dictionary we've stored the path in – think of it as unpacking a suitcase\n",
    "    # headless=False means that all of the browser's actions will be displayed in a Chrome window so we can see them.\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4590043d-302f-4d44-adab-3c3d46e689f7",
   "metadata": {},
   "source": [
    "Assign the URL and instruct the browser to visit it\n",
    "\n",
    "With the following line, browser.is_element_present_by_css('div.list_text', wait_time=1), we are accomplishing two things:\n",
    "1) We're searching for elements with a specific combination of tag (div) and attribute (list_text). As an example, ul.item_list would be found in HTML as ul class=\"item_list\".\n",
    "2) We're also telling our browser to wait one second before searching for components. The optional delay is useful because sometimes dynamic pages take a little while to load, especially if they are image-heavy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc0d44f6-0f16-4d70-be03-0927254d6987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visit the mars nasa news site\n",
    "url = 'https://redplanetscience.com'\n",
    "browser.visit(url)\n",
    "# Optional delay for loading the page\n",
    "    # Search for elements with a specific combination of tag (div) and attribute (list_text).\n",
    "    # Tell our browser to wait one second before searching for components\n",
    "browser.is_element_present_by_css('div.list_text', wait_time=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fb9b30-ec52-44cc-a3c8-183a8521f5dd",
   "metadata": {},
   "source": [
    "Use BeautifulSoup to parse the HTML. This means that BeautifulSoup has taken a look at the different components and can now access them. Specifically, BeautifulSoup parses the HTML text and then stores it as an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b96fb1c4-d4b7-4d88-816d-ca5a2a933c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the HTML parser using BeautifulSoup\n",
    "html = browser.html\n",
    "news_bs = bs(html, 'html.parser')\n",
    "# Assign slide_elem as the variable to look for the <div /> tag and its descendent (the other tags within the <div /> element)\n",
    "    # This means that this element holds all of the other elements within it, and we'll reference it when we want to filter search results even further.\n",
    "    # The . is used for selecting classes, such as list_text, so the code 'div.list_text' pinpoints the <div /> tag with the class of list_text. \n",
    "    # CSS works from right to left, such as returning the last item on the list instead of the first.\n",
    "    # Because of this, when using select_one, the first matching element returned will be a <li /> element with a class of slide and all nested elements within it.\n",
    "slide_elem = news_bs.select_one('div.list_text')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971dcc07-179a-4c7c-ad61-ea4b6d4c1074",
   "metadata": {},
   "source": [
    "After opening the page in a new browser, right-click to inspect and activate your DevTools. Then search for the HTML components you'll use to identify the title and paragraph you want.We'll want to assign the title and summary text to variables we'll reference later. \n",
    "\n",
    "In this line of code, we chained .find onto our previously assigned variable, slide_elem. When we do this, we're saying, \"This variable holds a ton of information, so look inside of that information to find this specific data.\" The data we're looking for is the content title, which we've specified by saying, \"The specific data is in a <div /> with a class of 'content_title'.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df93d72d-8d75-49b6-94b2-2906abdb8725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"content_title\">NASA's Mars Reconnaissance Orbiter Undergoes Memory Update</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chain .find onto our previously assigned variable, slide_elem and look for content title\n",
    "slide_elem.find('div', class_='content_title')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b61c372-867b-42c7-bf9e-7060b492254c",
   "metadata": {},
   "source": [
    "The title is in that mix of HTML in our output—that's awesome! But we need to get just the text, and the extra HTML stuff isn't necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a4ddc1a-0358-4c21-90ee-ec859ae0c5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------1st ARTICLE---------\n",
      "NASA's Mars Reconnaissance Orbiter Undergoes Memory Update\n",
      "-------------SUMMARY-------------\n",
      "Other orbiters will continue relaying data from Mars surface missions for a two-week period.\n"
     ]
    }
   ],
   "source": [
    "# Use the parent element to find the first `a` tag and save it as `news_title` variable\n",
    "    # When the .get_text() this method is chained onto .find(), only the text of the element is returned.\n",
    "news_title = slide_elem.find('div', class_='content_title').get_text()\n",
    "print(\"-------------1st ARTICLE---------\")\n",
    "print(news_title)\n",
    "\n",
    "# Use the parent element to find the paragraph text\n",
    "news_summary = slide_elem.find('div', class_=\"article_teaser_body\").get_text()\n",
    "print(\"-------------SUMMARY-------------\")\n",
    "print(news_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a997ba6-df50-4c32-9210-f482f20f426d",
   "metadata": {},
   "source": [
    "##### IMPORTANT\n",
    "There are two methods used to find tags and attributes with BeautifulSoup:\n",
    "* .find() is used when we want only the first class and attribute we've specified.\n",
    "* .find_all() is used when we want to retrieve all of the tags and attributes.\n",
    "For example, if we were to use .find_all() instead of .find() when pulling the summary, we would retrieve all of the summaries on the page instead of just the first one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0203ad-fdc6-4c27-a9f1-8f7625e2c81c",
   "metadata": {},
   "source": [
    "### Scrape Mars Data: Featured Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eedac72-6160-4d61-8742-720dc4674069",
   "metadata": {},
   "source": [
    "The first image that pops up on the webpage is the featured image. Robin wants the full-size version of this image, so we know we'll want Splinter to click the \"Full Image\" button. From there, the page directs us to a slideshow. It's a little closer to getting the full-size feature image, but we aren't quite there yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8611ad4a-4be0-4355-a728-cce2fc883b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit URL\n",
    "url = 'https://spaceimages-mars.com/'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a789238-cfe0-42ef-a781-b6e1c8d6a5fa",
   "metadata": {},
   "source": [
    "Next, we want to click the \"Full Image\" button. This button will direct our browser to an image slideshow. Let's take a look at the button's HTML tags and attributes with the DevTools.\n",
    "\n",
    "This is a fairly straightforward HTML tag: the \"button\" element has a two classes (btn and btn-outline-light) and a string reading \"FULL IMAGE\". First, let's use the dev tools to search for all the button elements.\n",
    "\n",
    "Since there are only three buttons, and we want to click the full-size image button, we can go ahead and use the HTML tag in our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4353d983-23a6-4be4-a1b0-4f8241cd3326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and click the full image button\n",
    "    # Assign a  new variable to hold the scraping result\n",
    "    # Use the browser finds to find an element by its tag\n",
    "    # Use index chaining at the end of first block of code to stipulate taht we want our browser to click the 2nd button\n",
    "full_image_elem = browser.find_by_tag(\"button\")[1]\n",
    "# Splinter will \"click\" the imagine to view its full size\n",
    "full_image_elem.click() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170cccb5-92a2-482c-b64f-040d2fe50ecb",
   "metadata": {},
   "source": [
    "With the new page loaded onto our automated browser, it needs to be parsed so we can continue and scrape the full-size image URL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "434293e9-e76d-4ba4-889f-0697acfe8e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the resulting html with soup\n",
    "html = browser.html\n",
    "img_bs = bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc97ce0-1c1f-425b-99b9-2bb0126134d3",
   "metadata": {},
   "source": [
    "Now we need to find the relative image URL. In our browser (make sure you're on the same page as the automated one), activate your DevTools again. This time, let's find the image link for that image. It's important to note that the value of the src will be different every time the page is updated, so we can't simply record the current value—we would only pull that image each time the code is executed, instead of the most recent one.\n",
    "\n",
    "We'll use the image tag and class (img /and fancybox-img) to build the URL to the full-size image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6743184-df79-41c7-9210-c5588f87260e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'image/featured/mars2.jpg'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the relative image url using BeautifulSoup to look inside the <img /> tag for an image with a class of fancybox-image\n",
    "    # An img tag is nested within this HTML, so we've included it.\n",
    "    # .get('src') pulls the link to the image.\n",
    "img_url_rel = img_bs.find('img', class_='fancybox-image').get('src')\n",
    "img_url_rel\n",
    "# Basically we're saying, \"This is where the image we want lives—use the link that's inside these tags.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe29cd2e-5d8b-4a94-86b5-747fc9de8d4a",
   "metadata": {},
   "source": [
    "Let's add the base URL to our code, because if we copy and paste this link into a browser, it won't work. This is because it's only a partial link, as the base URL isn't included. If we look at our address bar in the webpage, we can see the entire URL up there already; we just need to add the first portion to our app.\n",
    "\n",
    "We're using an f-string for this print statement because it's a cleaner way to create print statements; they're also evaluated at run-time. This means that it, and the variable it holds, doesn't exist until the code is executed and the values are not constant. This works well for our scraping app because the data we're scraping is live and will be updated frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "598c232d-fb35-4747-94b8-39cf65899252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://spaceimages-mars.com/image/featured/mars2.jpg'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the base URL to create an absolute URL\n",
    "    # img_url is the variable that holds our f string\n",
    "    # the f-string is a type of string formatting used for print statements in Python.\n",
    "    # {} The curly brackets hold a variable that will be inserted into the f-string when it's executed.\n",
    "img_url = f'https://spaceimages-mars.com/{img_url_rel}'\n",
    "img_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab23961a-a2e9-4bf7-ba14-a9d290a580df",
   "metadata": {},
   "source": [
    "### Scrape Mars Data: Mars Facts\n",
    "Get a table from Mars Facts and display it as a table on our own web app. Let's look at the webpage again, this time using our DevTools. All of the data we want is in a table / tag. \n",
    "\n",
    "Tables in HTML are basically made up of many smaller containers. The main container is the table / tag. Inside the table is tbody /, which is the body of the table—the headers, columns, and rows.\n",
    "\n",
    "tr / is the tag for each table row. Within that tag, the table data is stored in td / tags. This is where the columns are established.\n",
    "\n",
    "Instead of scraping each row, or the data in each td /, we're going to scrape the entire table with Pandas' .read_html() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "607cefcf-bad8-41cc-a0bd-66bff55d19ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mars</th>\n",
       "      <th>Earth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mars - Earth Comparison</th>\n",
       "      <td>Mars</td>\n",
       "      <td>Earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diameter:</th>\n",
       "      <td>6,779 km</td>\n",
       "      <td>12,742 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mass:</th>\n",
       "      <td>6.39 × 10^23 kg</td>\n",
       "      <td>5.97 × 10^24 kg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moons:</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Distance from Sun:</th>\n",
       "      <td>227,943,824 km</td>\n",
       "      <td>149,598,262 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Length of Year:</th>\n",
       "      <td>687 Earth days</td>\n",
       "      <td>365.24 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temperature:</th>\n",
       "      <td>-87 to -5 °C</td>\n",
       "      <td>-88 to 58°C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Mars            Earth\n",
       "description                                              \n",
       "Mars - Earth Comparison             Mars            Earth\n",
       "Diameter:                       6,779 km        12,742 km\n",
       "Mass:                    6.39 × 10^23 kg  5.97 × 10^24 kg\n",
       "Moons:                                 2                1\n",
       "Distance from Sun:        227,943,824 km   149,598,262 km\n",
       "Length of Year:           687 Earth days      365.24 days\n",
       "Temperature:                -87 to -5 °C      -88 to 58°C"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new DataFrame from the HTML table.\n",
    "    # The Pandas function read_html() specifically searches for and returns a list of tables found in the HTML.\n",
    "    # By specifying an index of 0, we're telling Pandas to pull only the first table it encounters, or the first item in the list.\n",
    "# Assign columns to the new DataFrame for additional clarity.\n",
    "# Use the .set_index() function, we're turning the Description column into the DataFrame's index\n",
    "    # inplace=True means that the updated index will remain in place, without having to reassign the DataFrame to a new variable.\n",
    "df = pd.read_html('https://galaxyfacts-mars.com/')[0]\n",
    "df.columns = ['description', 'Mars', 'Earth']\n",
    "df.set_index('description', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b3a494-d360-4507-9bb2-c7c67e14b2d9",
   "metadata": {},
   "source": [
    "Robin's web app is going to be an actual webpage. Thankfully, Pandas also has a way to easily convert our DataFrame back into HTML-ready code using the .to_html() function. \n",
    "\n",
    "The result is a slightly confusing-looking set of HTML code—it's a <table /> element with a lot of nested elements. This means success. After adding this exact block of code to Robin's web app, the data it's storing will be presented in an easy-to-read tabular format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8e4ae52-90ec-49bd-9f24-3ef95ee9810a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>Mars</th>\\n      <th>Earth</th>\\n    </tr>\\n    <tr>\\n      <th>description</th>\\n      <th></th>\\n      <th></th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>Mars - Earth Comparison</th>\\n      <td>Mars</td>\\n      <td>Earth</td>\\n    </tr>\\n    <tr>\\n      <th>Diameter:</th>\\n      <td>6,779 km</td>\\n      <td>12,742 km</td>\\n    </tr>\\n    <tr>\\n      <th>Mass:</th>\\n      <td>6.39 × 10^23 kg</td>\\n      <td>5.97 × 10^24 kg</td>\\n    </tr>\\n    <tr>\\n      <th>Moons:</th>\\n      <td>2</td>\\n      <td>1</td>\\n    </tr>\\n    <tr>\\n      <th>Distance from Sun:</th>\\n      <td>227,943,824 km</td>\\n      <td>149,598,262 km</td>\\n    </tr>\\n    <tr>\\n      <th>Length of Year:</th>\\n      <td>687 Earth days</td>\\n      <td>365.24 days</td>\\n    </tr>\\n    <tr>\\n      <th>Temperature:</th>\\n      <td>-87 to -5 °C</td>\\n      <td>-88 to 58°C</td>\\n    </tr>\\n  </tbody>\\n</table>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721c5ae8-64c0-4396-b7e8-4f87d0c0bef0",
   "metadata": {},
   "source": [
    "Now that we've gathered everything on Robin's list, we can end the automated browsing session. This is an important line to add to our web app also. Without it, the automated browser won't know to shut down—it will continue to listen for instructions and use the computer's resources (it may put a strain on memory or a laptop's battery if left on). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3efb5a36-7b8e-4742-a160-b79b1a1a781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ded127-5b22-49e4-8caf-213bb7b0dc9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
